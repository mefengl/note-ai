// filepath: /Volumes/MI-1T/Developer/GitHub/note-ai/examples/node-http-server/src/server.ts

/**
 * 基于Node.js的AI文本生成服务器示例
 * ================================
 * 
 * 本文件实现了一个简单的Node.js HTTP服务器，展示了如何使用AI SDK与OpenAI模型进行交互。
 * 该服务器提供两种不同的响应流方式：
 * 1. 基础流式响应：直接将AI生成的文本以流的形式返回给客户端
 * 2. 高级数据流：在返回AI生成内容的同时，可以发送自定义消息和处理错误
 * 
 * 这个例子完美展示了如何在不依赖任何Web框架(如Express)的情况下，
 * 使用Node.js原生HTTP能力构建AI文本生成服务。
 */

// 从AI SDK导入OpenAI提供商适配器
import { openai } from '@ai-sdk/openai';

// 导入AI SDK的核心流处理工具
// - streamText：用于生成文本流
// - pipeDataStreamToResponse：将数据流直接输出到HTTP响应
import { pipeDataStreamToResponse, streamText } from 'ai';

// 加载环境变量（如OPENAI_API_KEY）
// 提示：你需要创建一个.env文件并设置OPENAI_API_KEY=你的OpenAI API密钥
import 'dotenv/config';

// 导入Node.js原生HTTP服务器创建功能
import { createServer } from 'http';

// 创建一个HTTP服务器并立即监听8080端口
createServer(async (req, res) => {
  // 根据请求的URL路径选择不同的处理方式
  switch (req.url) {
    // 处理根路径请求 - 基础流式文本生成
    case '/': {
      // 使用streamText函数创建一个流式文本生成器
      // 这是最简单的使用方式：直接指定模型和提示词
      const result = streamText({
        model: openai('gpt-4o'),  // 使用OpenAI的GPT-4o模型
        prompt: 'Invent a new holiday and describe its traditions.',  // 要求AI发明一个新节日并描述其传统
      });
      
      // 将生成的文本流直接管道输出到HTTP响应
      // 客户端将收到流式传输的文本，随着AI生成而不断更新
      result.pipeDataStreamToResponse(res);
      break;
    }

    // 处理"/stream-data"路径 - 高级数据流处理
    case '/stream-data': {
      // 立即开始流式输出响应
      // 这种方式提供了更多控制，允许在AI响应生成前后发送自定义数据
      pipeDataStreamToResponse(res, {
        // 执行函数接收一个dataStreamWriter参数，用于写入数据流
        execute: async dataStreamWriter => {
          // 首先发送一条初始化消息
          // 这在用户等待AI响应开始时提供即时反馈
          dataStreamWriter.writeData('initialized call');

          // 然后创建文本流生成器，与根路径处理相同
          const result = streamText({
            model: openai('gpt-4o'),
            prompt: 'Invent a new holiday and describe its traditions.',
          });

          // 将AI生成的文本流合并到已经建立的数据流中
          // 这意味着AI内容会跟随在我们的初始化消息之后
          result.mergeIntoDataStream(dataStreamWriter);
        },
        
        // 错误处理函数
        // 当生成过程中出现任何错误时被调用
        onError: error => {
          // 默认情况下，错误信息会被屏蔽以保证安全
          // 这里我们可以选择向客户端暴露错误信息
          // 在生产环境中，应该谨慎处理这部分，避免泄露敏感信息
          return error instanceof Error ? error.message : String(error);
        },
      });
      break;
    }
  }
}).listen(8080);  // 服务器监听在8080端口

/**
 * 使用说明
 * ========
 * 
 * 1. 启动服务器后，可以通过浏览器访问:
 *    - http://localhost:8080/ - 查看基础文本流
 *    - http://localhost:8080/stream-data - 查看带初始化消息的高级数据流
 * 
 * 2. 实际应用场景:
 *    - 聊天机器人后端API
 *    - AI内容生成服务
 *    - 实时文本补全和建议系统
 * 
 * 3. 为什么使用流式响应?
 *    - 提升用户体验：用户可以看到逐步生成的内容，而不必等待完整响应
 *    - 减少感知延迟：即使生成大量内容也能快速开始显示
 *    - 支持长时间运行的生成：适用于生成详细回复的场景
 */
